{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrega 3, Inteligencia Artificial**, UNAL sede Bogota.\n",
    "Integrantes: Marco Fidel Caro Durán, Alexis Orlando Sánchez Virgüez, Nils Peer Beck\n",
    "\n",
    "# **NLP en calificaciones: Mapeando texto a números correspondientes**\n",
    "---\n",
    "\n",
    "Este proyecto se trata de procesamiento de lenguage natural en el contexto de aprendizaje de máquina supervisado.\n",
    "\n",
    "## Objetivo\n",
    "Queremos construir un modelo que a partir de un texto puede predecir una calificación entre 1 y 5 estrellas.\n",
    "\n",
    "## Contexto\n",
    "Dicho modelo podría servir en plataformas muy dependientes de evaluaciones dentro de la comunidad, por ejemplo servicios de taxis (Uber, Beat, Didi, etc.) o plataformas de compra (Mercado Libre, Amazon, Rappi). Lo que hacemos en esencia es un análisis de sentimientos dentro del texto escrito. Aunque abstraemos mucho de este sentimiento y lo representamos solamente en un número entre 1 y 5, por lo general este area tiene muchas aplicaciones, ya que es cada vez más necesario que las computadoras nos entienden mejor a los humanos.\n",
    "\n",
    "## Metodología\n",
    "Para llegar hasta un modelo funcional, tenemos que pasar por varias etapas. Primero, necesitamos datos que sirven para el entrenamiento y la validación. Obtener estos datos y representarlos de manera adequada ya es una gran parte de nuestro trabajo.\n",
    "\n",
    "Una vez obtenidos los datos elegimos un modelo adecuado, lo entrenamos y presentamos los resultados. Encuentre todos los detalles abajo.\n",
    "\n",
    "## Estado del arte\n",
    "Todos los individuos somos seres sociales y dentro de las necesidades que tenemos está el formar parte de un grupo o pertenecer a una comunidad especifica. Dicha acción de sentirse aceptado por un determinado grupo nos lleva a prestar atención a las opiniones de los demás, como en el caso de la opinión pública, la cual es un factor muy influyente en la realidad política, social y cultural de un determinado sitio. Surge entonces dentro de la Inteligencia artificial el campo de procesamiento del lenguaje natural, y así el análisis de sentimientos, cuya finalidad es el tratamiento  computacional de las opiniones. Dentro de los trabajos que se han realizado en esta área, está el de Lucas Montesinos García de la Universidad de Chile, el cual realizo predicciones de los  opiniones de los usuarios mediante la plataforma twitter; o el trabajo de Cesar Aguirre de la Universidad de Castilla-La Mancha (España) estudiando el  análisis de sentimiento en redes sociales para la preinscripción de situaciones financieras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilar datos\n",
    "Para este proyecto vamos a usar datos de la página https://www.losestudiantes.co. En ella se encuentran perfiles de profesores y asignaturas de la Universidad de los Andes y la Universidad Nacional de Colombia, sede Bogotá, creados anónimamente por estudiantes.\n",
    "\n",
    "Nos interesa mapear el texto de las calificaciones que dejan los estudiantes a la cantidad de estrellas (entre 1 y 5) correspondiente. Es decir que buscamos predecir esta calificación a partir del texto escrito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar URLs relevantes\n",
    "Como primer paso identificamos todos los _Unique Resource Locators_ (URLs) que nos pueden servir para obtener dichos datos. Para ello usamos un servicio en línea, permitiendonos crear una lista de todas las subpáginas de https://www.losestudiantes.co. De estas subpáginas filtramos por todas aquellas que son de la estructura https://www.losestudiantes.co/UNIVERSIDAD/DEPARTAMENTO/profesores/NOMBRE_DEL_PROFESOR.\n",
    "Un ejemplo sería la URL https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/fabio-ortiz-guzman. \n",
    "\n",
    "Almacenamos la lista de todas las URLs restantes en el archivo _prof_names.txt_.\n",
    "**Cada entrada en la lista corresponde a una subpágina que contine cero o más calificaciones.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/fabio-ortiz-guzman\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/rafael-montoya-robledo\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/alexander-getmanenko\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/schweitzer-rocuts\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/mauricio-velasco-grigori\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/carolina-benedetti-velasquez\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/diego-antonio-robayo-bargans\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/william-leonardo-pacheco-tobo\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/juan-felipe-uribe-morales\n",
      "\n",
      "https://losestudiantes.co/universidad-de-los-andes/matematicas/profesores/german-augusto-tobar-bravo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run this cell to have a look at the file prof_names.txt\n",
    "def head(filename, lines):\n",
    "    with open(filename, \"r\") as file:\n",
    "        head = [next(file) for x in range(lines)]\n",
    "\n",
    "    for line in head:\n",
    "        print (line)\n",
    "    \n",
    "head(\"prof_names.txt\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer calificaciones de las URLs (web scraping)\n",
    "Dadas las URLs que pueden contener calificaciones, nos ponemos ahora a extraer estas calificaciones de ellas.\n",
    "Para ello usamos la librería _selenium_, la cual nos permite manejar un navegador web - en nuestro caso Firefox - de forma automática. Es decir, abrimos una URL, bajamos todos los datos de calificaciones que nos interesen y seguimos con la próxima.\n",
    "\n",
    "Más específicamente, trabajamos de la siguiente forma:\n",
    "\n",
    "1. Abrir URL\n",
    "2. Identificar todos los componentes marcados como \"posts\", es decir, publicaciones conteniendo calificaciones\n",
    "3. Extraer el texto y la calificacion en números "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,rating_number,rating_text\n",
      "\n",
      "0,3.7,\"En general la clase con Catalina es buena pero existen graves falencias que muchas veces cuestionan la calidad del curso, Catalina suele llegar tarde a clase y faltar en reiteradas ocasiones, las retroalimentaciones suelen ser duras y a veces se siente cierta ironía por parte de ella, existe una clara preferencia por ciertos estudiantes, hay mucho desorden en el programa y las temáticas.\"\n",
      "\n",
      "1,5,\"¡Una de las mejores profesoras! Sus clases son muy entretenidas, es un amor de persona y siempre se esmera para que cada uno de sus estudiantes comprenda.\"\n",
      "\n",
      "2,4.7,\"Se preocupa por el aprendizaje de sus estudiantes, explica bien y siempre esta dispuesto a resolver dudas y corregir errores de la mejor manera.\"\n",
      "\n",
      "3,3,\"Es un buen profesor; es chistoso, hace la clase amena. Los parciales son acordes a lo que enseña. Sin embargo, cumple el programa estrictamente, es decir, lo que se tiene que ver en una clase se ve, aun así existan dudas, el siempre va muy rápido en todo por esto. Uno se confunde mucho en clase y como va tan rápido no da tanta confianza para pregun...\"\n",
      "\n",
      "4,3,\"Sus parciales tienen el mismo nivel de dificultad que los de Dario, sus tareas son muy buenas para prepararse pero demasiado largas. Su clase es demasiado tediosa por lo cual hace que se pierda el intereses por la materia. Es muy organizada y ofrece buen material. Ya no es tan dificil como antes pues no se hacen quices.\"\n",
      "\n",
      "5,1,\"Es una profesora vengativa, que muy a pesar de saber mucho sobre la materia no es para nada fácil de llevar y puede dejar la clase tirada si le da la gana. Literal cambio la forma de evaluar como venganza hacia el curso en TGE.\"\n",
      "\n",
      "6,5,\"Es un excelente profesor, explica muy bien todos los temas, se esfuerza para que todos los estudiantes entiendan todo, atiende las dudas, se interesa en que sus estudiantes aprendan y hace la clase agradable. Los parciales no son fáciles pero de verdad que aprendes mucho con este profesor. Es lo máximo!\"\n",
      "\n",
      "7,5,Es muy ordenada y explica muy bien.\n",
      "\n",
      "8,3,\"Es un profesor que no explica muy bien por lo rápido que dicta la clase, simplemente espera que uno haya entendido todo y no le gusta responder dudas sobre los temas\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "\n",
    "# file containing the professors' URLs\n",
    "prof_names = open('prof_names.txt', 'r')\n",
    "\n",
    "\n",
    "def scrape_the_URLs():\n",
    "    # for unique identification of each data compound\n",
    "    # make sure id_number is initialized\n",
    "    id_number = 0\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    # Create file to store data resulting from web scraping\n",
    "    with open('web_scraping_results.csv', 'w') as results:\n",
    "        fieldnames = ['id', 'rating_number', 'rating_text']\n",
    "        filewriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        filewriter.writeheader()\n",
    "    \n",
    "        # process URLs one by one\n",
    "        for line in prof_names.readlines():\n",
    "            driver.get(line)\n",
    "\n",
    "            # get all available posts on the URL and store them in CSV results file\n",
    "            for post in driver.find_elements_by_class_name('post'):\n",
    "                lines = post.splitlines()\n",
    "                \n",
    "                # only process non-empty lines (empty ones would throw error later on)\n",
    "                if (len(lines[0]) > 0 and len(lines[1]) > 0):\n",
    "                    filewriter.writerow({'id':id_number, 'rating_number':lines[0], 'rating_text':lines[1]})\n",
    "                    id_number += 1\n",
    "\n",
    "    # close the connection\n",
    "    driver.quit()\n",
    "    \n",
    "\n",
    "# display the head of web_scraping_results.csv\n",
    "head(\"web_scraping_results.csv\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar los datos para el modelo\n",
    "Ahora que ya tenemos los datos (casi) listos para trabajar, necesitamos entrenar un modelo con ellos. Eligimos la librería _FastText_ (https://www.fasttext.cc) para ello.\n",
    "Sin embargo, antes de poder entrenar el modelo, tenemos que preprocesar nuestros datos (a) para que sirvan y (b) para que _FastText_ los entienda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "Tomamos tres pasos para mejorar la calidad de los datos para el entrenamiento del modelo\n",
    "\n",
    "1. Tokenizamos los datos: \n",
    "Es decir, separamos un _string_ en _tokens_ , o sea, componentes atomicos. Por ejemplo, _\"Hola, soy Nils\"_ se convierte en los tokens [\"hola\", \"soy\", \",\", \"Nils\"]. Usamos los servicios del grupo de investigación _Stanford Natural Language Processing_ (https://nlp.stanford.edu/software/tokenizer.html).\n",
    "\n",
    "2. Eliminamos los _stop words_:\n",
    "Es decir, quitamos todas las palabras que no sean significativas para el texto. Usamos como referencia la lista del _Natural Language Toolkit_ (https://www.nltk.org) para el Castellano.\n",
    "\n",
    "3. Enraizamos las palabras:\n",
    "Es decir, representamos palabras de la misma raíz como una misma palabra. Esto mejore la calidad de las predicciones.\n",
    "Las palabras _\"bonito\"_ y _\"bonita\"_ , por ejemplo, las representamos ambas como _\"bonit\"_. Usamos la librería _Stemmer_ del Proyecto _Snowball_ (https://snowballstem.org/).\n",
    "\n",
    "## Almacenar los datos procesados en formato leíble para FastText\n",
    "FastText no entiende el formato CSV, asi que vamos a tener que cambiar nuestros datos procesados un poco. En vez de CSV vamos a usar el formato TXT con cada línea siguiendo el esquema _texto_ \\_\\_label \\_\\_ _etiqueta_.\n",
    "\n",
    "Un ejemplo sería: \n",
    "\n",
    "El profesor es pésimo \\_\\_label\\_\\_1.5\n",
    "\n",
    "## Crear subconjuntos para entrenamiento y validación\n",
    "Usando el formato de _FastText_ descrito en el párrafo arriba, creamos dos subconjuntos de datos:\n",
    "\n",
    "- Datos de entrenamiento (50% de los datos originales):\n",
    "Este conjunto lo usaremos para entrenar nuestro modelo.\n",
    "- Datos de validación (50% de los datos originales):\n",
    "Este conjunto lo usaremos para ver que tanto sirve nuestro modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import stanfordnlp\n",
    "import Stemmer\n",
    "import nltk\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to block undesired output temporarily\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "# only needs to be run once\n",
    "# downloads all necessary stemming and stopword data\n",
    "def prepare_preprocess():\n",
    "    stanfordnlp.download('es')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def tokenize(string):\n",
    "    # load string into stanfordnlp model\n",
    "    nlp = stanfordnlp.Pipeline(processors='tokenize', lang=\"es\")\n",
    "    doc = nlp(string)\n",
    "    \n",
    "    # produce a list of only the relevant text in the tokens\n",
    "    tokens_lst = []\n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            for word in token.words:\n",
    "                tokens_lst.append(word.text)\n",
    "\n",
    "    return tokens_lst\n",
    "\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    # exclude spanish stopwords as well as words of length 1 (i.e. most probably symbols)\n",
    "    return [w for w in tokens\n",
    "            if w not in nltk.corpus.stopwords.words('spanish')\n",
    "            and len(w) > 1]\n",
    "\n",
    "def stem(tokens):\n",
    "    # replace words with their stems\n",
    "    stemmer = Stemmer.Stemmer('spanish')\n",
    "    return stemmer.stemWords(tokens)\n",
    "\n",
    "\n",
    "def preprocess(string):\n",
    "    if len(string) == 0:\n",
    "        return \"\"\n",
    "    tokens = tokenize(string)\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    if len(tokens) == 0:\n",
    "        return \"\"\n",
    "    tokens = stem(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def write_data():\n",
    "    blockPrint()\n",
    "    \n",
    "    # open corresponding files\n",
    "    in_training_set = True\n",
    "    with open('training_set.txt', 'w') as training_set:\n",
    "        with open('test_set.txt', 'w') as test_set:\n",
    "            with open('web_scraping_results', 'r') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for line in reader:\n",
    "                    if in_training_set:\n",
    "                        our_set = training_set\n",
    "                    else:\n",
    "                        our_set = test_set\n",
    "\n",
    "                    # write out information in fasttext format\n",
    "                    processed_text_rating = str(preprocess(line[\"rating_text\"]))\n",
    "\n",
    "                    if processed_text_rating != \"\":\n",
    "                        our_set.write(processed_text_rating + \" __label__\" + str(line[\"rating_number\"]) + \" \\n\")\n",
    "                        in_training_set = not in_training_set\n",
    "\n",
    "                training_set.close()\n",
    "                test_set.close()\n",
    "    enablePrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar el modelo\n",
    "Ahora sí tenemos los datos preprocesados y en el formato necesario para entrenar un modelo de _FastText_.\n",
    "\n",
    "En el siguiente párrafo creamos entonces un modelo supervisado con _FastText_. La gran mayoría de métodos y funciones que facilita esta libería se pueden entender como interfaces abstractos. Es decir que con poco conocimiento sobre aprendizaje de máquina, pero también con pocas líneas de código podemos entrenar el siguiente modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "def create_model():\n",
    "    # train model\n",
    "    model = fasttext.train_supervised('training_set.txt')\n",
    "    \n",
    "    # save model\n",
    "    model.save_model('model.bin')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validar el modelo\n",
    "Ya entrenado el modelo nos falta validarlo. Así que medimos qué tan exacto son sus predicciones.\n",
    "\n",
    "Sin embargo, antes de ello proveemos al lector con un método permitiéndolo a sacar sus propias conclusiones y jugar un poco con el modelo que construimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__3',), array([0.1178445]))\n",
      "(('__label__4',), array([0.1091632]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model_manually(text):\n",
    "    model = fasttext.load_model('model.bin')\n",
    "    print(model.predict(text))\n",
    "    \n",
    "test_model_manually(\"No sirve la clase\")\n",
    "test_model_manually(\"Me encanta la clase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación: \n",
      "\n",
      "Cantidad de muestras N\t\t7390\n",
      "Precisión en 1 P@1\t\t0.367\n",
      "Sensibilidad en 1 R@1\t\t0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"Resultados de la validación: \\n\")\n",
    "    # number of samples\n",
    "    print(\"Cantidad de muestras N\\t\\t\" + str(N))\n",
    "    \n",
    "    # precision at 1\n",
    "    print(\"Precisión en 1 P@{}\\t\\t{:.3f}\".format(1, p))\n",
    "    \n",
    "    # recall at 1\n",
    "    print(\"Sensibilidad en 1 R@{}\\t\\t{:.3f}\".format(1, r))\n",
    "\n",
    "def test_model():\n",
    "    model = fasttext.load_model('model.bin')\n",
    "    print_results(*model.test('test_set.txt'))\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen\n",
    "\n",
    "## Logros\n",
    "En esencia, hemos logrado lo que buscamos hacer en este proyecto. Entregamos un modelo funcional, entrenado con alrededor de 7500 unidades de datos, permitiéndonos predecir el sentimiento de un texto, representado en 1 a 5 estrellas.\n",
    "\n",
    "## Limitaciones\n",
    "Aunque sí entregamos un modelo funcional, este modelo no cuenta con las características deseables: La precisión es de 36,7%, es decir bastante baja. En un \"buen\" modelo esperaríamos alrededor de 95% de precisión.\n",
    "\n",
    "Sin embargo, esta precisón no mide predicciones \"casi correctas\", como por ejemplo una de 3.4 en vez de 3.5, porque cada etiqueta cuenta como un resultado completamente distinto. Suponemos que si evaluamos las predicciones con 0.3 estrellas de desviación, obtendríamos resultados mucho mejores.\n",
    "\n",
    "## Propuestas para futuros trabajos\n",
    "Para mejorar el modelo, proponemos usar más datos, a lo mejor también de otras fuentes. También se podría considerar partir los conjuntos de datos de entrenamiento y de validadación de forma más desigual. Por ejemplo, se podrían dividir en 80% de los datos para entrenamiento y 20% para la validación.\n",
    "\n",
    "En general, el tema nos parece muy interesante desde el punto de vista investigativo. Seguramente habrá muchas áreas en las que se puede aplicar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
